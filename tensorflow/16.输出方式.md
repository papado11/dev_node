# 16 输出方式

## 16.1 sigmoid

将输入映射到0~1的范围

```python
a = tf.linspace(-6., 6, 10)
a
# <tf.Tensor: shape=(10,), dtype=float32, numpy=
# array([-6.       , -4.6666665, -3.3333333, -2.       , -0.6666665,
#         0.666667 ,  2.       ,  3.333334 ,  4.666667 ,  6.       ],
#       dtype=float32)>
tf.sigmoid(a)
# <tf.Tensor: shape=(10,), dtype=float32, numpy=
# array([0.00247262, 0.00931596, 0.0344452 , 0.11920292, 0.33924368,
#        0.6607564 , 0.880797  , 0.96555483, 0.99068403, 0.9975274 ],
#       dtype=float32)>
```

## 16.2 tf.nn.softmax

多分类输出和为1

```python
a = tf.linspace(-6., 6, 10)
tf.nn.softmax(a)
# <tf.Tensor: shape=(10,), dtype=float32, numpy=
# array([4.5246225e-06, 1.7164926e-05, 6.5118002e-05, 2.4703599e-04,
#        9.3717274e-04, 3.5553225e-03, 1.3487710e-02, 5.1167920e-02,
#        1.9411406e-01, 7.3640394e-01], dtype=float32)>
a = tf.random.uniform([3, 3], minval=-2, maxval=2)
# <tf.Tensor: shape=(3, 3), dtype=float32, numpy=
# array([[ 1.3327432 ,  1.1839552 , -1.8476968 ],
#        [-0.62549925, -1.9270425 ,  1.2810931 ],
#        [ 0.57245207, -0.5362668 , -1.2591429 ]], dtype=float32)>
prob = tf.nn.softmax(a)
# <tf.Tensor: shape=(3, 3), dtype=float32, numpy=
# array([[0.52539796, 0.45276263, 0.02183941],
#        [0.12496521, 0.03400448, 0.8410303 ],
#        [0.67107815, 0.22144334, 0.10747849]], dtype=float32)>
tf.reduce_sum(prob, axis=1)
# <tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>
```

## 16.2 tf.nn.tanh

将输入映射到-1~1的范围

```python
a = tf.linspace(-6., 6, 10)
# <tf.Tensor: shape=(10,), dtype=float32, numpy=
# array([-6.       , -4.6666665, -3.3333333, -2.       , -0.6666665,
#         0.666667 ,  2.       ,  3.333334 ,  4.666667 ,  6.       ],
#       dtype=float32)>
tf.tanh(a)
# <tf.Tensor: shape=(10,), dtype=float32, numpy=
# array([-0.9999876 , -0.99982315, -0.99745804, -0.9640276 , -0.58278286,
#         0.58278316,  0.9640276 ,  0.99745804,  0.99982315,  0.9999876 ],
#       dtype=float32)>
```
